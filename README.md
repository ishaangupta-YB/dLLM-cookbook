# dLLM Cookbook

This repository is a cookbook of examples for implementing Inception Labs's dLLM (diffusing Large Language Models). It provides various examples of how to integrate dLLM into your applications, from simple HTML files to full-stack applications.

## Examples

This cookbook contains the following examples:

-   **[HTML Example](./examples/html-example)**: Simple, self-contained HTML files that demonstrate both `streaming` and `diffusing` responses from dLLM. A great place to start to understand the core concepts.

-   **[Streamlit Example](./examples/streamlit-example)**: Two Streamlit applications that showcase how to build interactive chat interfaces with dLLM. One is a  chat client, and the other demonstrates how to use "tools" (like web search) with the model.

-   **[Next.js Example](./examples/nextjs-example)**: A full-featured chat application built with Next.js, TypeScript, and Tailwind CSS. It demonstrates how to build a modern, streaming-first chat interface for dLLM.

-   **[FastAPI-React Example](./examples/fastapi-react-example)**: (Placeholder) This directory is intended for a future example demonstrating how to use dLLM with a FastAPI backend and a React frontend.

## Getting Started

Each example directory contains its own `README.md` file with detailed instructions on how to set up and run the example. Please refer to the `README.md` in each directory for more information.

## Contributing

Contributions are welcome! If you have an idea for a new example or want to improve an existing one, please feel free to open an issue or submit a pull request.
